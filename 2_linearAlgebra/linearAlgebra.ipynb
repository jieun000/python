{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5910a34",
   "metadata": {},
   "source": [
    "Menu\n",
    "<div>\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td rowspan=\"5\">linear regression</td>\n",
    "            <td>선형회귀란?</td>\n",
    "        </tr>\n",
    "        <tr><td>경사하강법</td></tr>\n",
    "        <tr><td>선형회귀</td></tr>\n",
    "        <tr><td>𝑓𝑒𝑎𝑡𝑢𝑟𝑒가 하나일 때</td></tr>\n",
    "        <tr><td>𝑓𝑒𝑎𝑡𝑢𝑟𝑒가 여러 개이며  𝑡𝑟𝑎𝑖𝑛𝑖𝑛𝑔𝑑𝑎𝑡𝑎(6쌍)</td></tr>\n",
    "    </table>\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td rowspan=\"5\">logistic regression</td>\n",
    "            <td>로지스틱 회귀란?</td>\n",
    "        </tr>\n",
    "        <tr><td>Hessian 행렬</td></tr>\n",
    "        <tr><td>1</td></tr>\n",
    "        <tr><td>2</td></tr>\n",
    "        <tr><td>3</td></tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dbfb01",
   "metadata": {},
   "source": [
    "## 선형회귀(linear regression)란?\n",
    "- feature와 label은 항상 쌍으로 주어지고, feature가 하나인 것을 simple linear regression이라고 하고\n",
    "- feature가 여러 개 있고 label이 하나 있는 것을 multivariable linear regression이라고 함.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>x(feature/시간)</th>\n",
    "        <th>y(label(정답)/점수)</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>10</td>\n",
    "        <td>90</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>9</td>\n",
    "        <td>8</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>3</td>\n",
    "        <td>50</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>2</td>\n",
    "        <td>30</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "데이터가 여러 개가 있고 여러 개의 데이터를 하나의 점으로 생각하고 벡터로 생각하자 <br>\n",
    "여러 개의 점과 가장 오차가 적게 되는 직선의 방정식(hypothesis / $ \\hat{y} $) 과의 차이가 적게 $ \\hat{y} $ 이 계속 움직이면서 오차를 적게 하려는 방향으로 학습(갱산, w와 b를 변경)하면서 cost(오차, Mean Square Error)가 0으로 가까워지도록 학습을 하게 되면 우리가 찾고자 하는 y(정답)과 가장 가까운 $ \\hat{y} $ 을 찾게되는 것이고 그것이 linear regression의 학습이 완료된 것이다.-\n",
    "$$ J = \\frac{1}{2m}\\sum_{i=1}^{m}(y-\\hat{y})^{2} \\rightarrow MSE $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b45797a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80754ba7",
   "metadata": {},
   "source": [
    "# Optional Lab: 선형회귀를 위한 경사 하강법 <br>(Gradient Descent for Linear Regression)\n",
    "\n",
    "<figure>\n",
    "    <center> <img src=\"./images(1)/C1_W1_L4_S1_Lecture_GD.png\"  style=\"width:800px;height:200px;\" ></center>\n",
    "    <figcaption>$$ pred = x \\cdot w + b $$</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527c0656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(self, x, y):\n",
    "    pred = np.dot(x, self.w)+ self.b # 예측한 직선의 방정식(y^hat, hypothesis(가설))\n",
    "    e = y - pred # 오차\n",
    "    return np.mean(e**2) # Mean Square Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e51dad",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(w,b)}{\\partial w}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})x^{(i)} \\tag{4}\\\\\n",
    "  \\frac{\\partial J(w,b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)}) \\tag{5}\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\\begin{align*} \\text{ 수렴할 때까지 반복:} \\; \\lbrace \\newline\n",
    "\\;  w &= w -  \\alpha \\frac{\\partial J(w,b)}{\\partial w} \\tag{3}  \\; \\newline \n",
    " b &= b -  \\alpha \\frac{\\partial J(w,b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2d4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self,x,y): # 반복하여 w, b를 찾음\n",
    "    pred = x@self.w + self.b\n",
    "    e = y - pred\n",
    "    dJ_dw = (np.mean(e*(-2*x), axis=0)) # J를 w로 편미분, 0or1에 따라 가로로 세로로\n",
    "    dJ_db = (np.mean(e*(-2), axis=0)) # J를 b로 편미분\n",
    "    self.w = (self.w.T - self.lr*dJ_dw).T # w갱신\n",
    "    self.b = (self.b.T - self.lr*dJ_db) # b갱신"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f2b230",
   "metadata": {},
   "source": [
    "*gradient descent(경사 하강)*  는 아래와 같다\n",
    "\n",
    "$$\\begin{align*} \\text{ 수렴할 때까지 반복:} \\; \\lbrace \\newline\n",
    "\\;  w &= w -  \\alpha \\frac{\\partial J(w,b)}{\\partial w} \\tag{3}  \\; \\newline \n",
    " b &= b -  \\alpha \\frac{\\partial J(w,b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "여기서 파라미터는 $w$, $b$ 이고 동시에 갱신됨. \n",
    "기울기는 아래와 같다:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(w,b)}{\\partial w}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})x^{(i)} \\tag{4}\\\\\n",
    "  \\frac{\\partial J(w,b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)}) \\tag{5}\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    " *simultaniously* 는 모든 파라미터를 갱신하기 전에 모든 파라미터의 편미분을 계산하는 것을 의미함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bde2ab",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial J(w,b)}{\\partial w} = ? $$\n",
    "\n",
    "$$ J = \\frac{1}{2m}\\sum_{i=1}^{m}(y-\\hat{y})^{2} \\rightarrow MSE $$\n",
    "$$ J = \\frac{1}{2m}\\sum_{i=1}^{m}(y-(wx+b))^{2} \\rightarrow MSE $$\n",
    "$$ wx+b \\rightarrow p $$\n",
    "$$ y-\\hat{y} \\rightarrow q $$\n",
    "$$ y-p \\rightarrow q $$\n",
    "$$  J = \\frac{1}{2m}\\sum_{i=1}^{m}q^{2} $$\n",
    "$$ \\frac{\\partial J(w,b)}{\\partial q} =  \\frac{1}{2m}\\sum_{i=1}^{m} 2q $$\n",
    "$$ \\frac{\\partial p}{\\partial w} = x $$\n",
    "$$ \\frac{\\partial J}{\\partial q} \\frac{\\partial q}{\\partial p} \\frac{\\partial p}{\\partial w} = $$\n",
    "$$ \\frac{1}{m}\\sum_{i=1}^{m}(y-\\hat{y}) \\cdot (-1) \\cdot x  $$\n",
    "$$ -\\frac{1}{m}\\sum_{i=1}^{m}(y-\\hat{y}) \\cdot x  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80aa28f",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial J(w,b)}{\\partial b} = ? $$\n",
    "\n",
    "$$ J = \\frac{1}{2m}\\sum_{i=1}^{m}(y-\\hat{y})^{2} \\rightarrow MSE $$\n",
    "$$ J = \\frac{1}{2m}\\sum_{i=1}^{m}(y-(wx+b))^{2} \\rightarrow MSE $$\n",
    "$$ wx+b \\rightarrow p $$\n",
    "$$ y-\\hat{y} \\rightarrow q $$\n",
    "$$ y-p \\rightarrow q $$\n",
    "$$ \\frac{\\partial J}{\\partial b} =  \\frac{\\partial J}{\\partial q} \\frac{\\partial q}{\\partial p} \\frac{\\partial p}{\\partial b} = $$\n",
    "$$  J = \\frac{1}{2m}\\sum_{i=1}^{m}q^{2} $$\n",
    "$$ \\frac{\\partial J(w,b)}{\\partial q} =  \\frac{1}{2m}\\sum_{i=1}^{m} 2q $$\n",
    "$$ \\frac{\\partial p}{\\partial w} = x $$\n",
    "$$ \\frac{\\partial q}{\\partial p} = -1 $$\n",
    "$$ \\frac{1}{m}\\sum_{i=1}^{m}(y-\\hat{y}) \\cdot (-1) \\cdot x  $$\n",
    "$$ -\\frac{1}{m}\\sum_{i=1}^{m}(y-\\hat{y}) \\cdot x  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93c79b9",
   "metadata": {},
   "source": [
    "# linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e011ca2d",
   "metadata": {},
   "source": [
    "<img src='./images(1)/linear1.gif' width=\"30%\" style=\"float: left;\"/>\n",
    "<img src='./images(1)/linear2.gif' width=\"30%\" style=\"float: left;\"/>\n",
    "<img src='./images(1)/linear3.gif' width=\"30%\" style=\"float: left;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845e1f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1f5e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install celluloid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9647144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import celluloid \n",
    "from celluloid import Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021edac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(object):\n",
    "    def __init__(self, w=1, b=1, lr=0.01):\n",
    "        self.lr = lr\n",
    "        self.w = np.array([[w]]) # w: 행렬\n",
    "        self.b = np.array([[b]]) # b: 벡터\n",
    "    def cost(self, x, y):\n",
    "        pred = x@self.w + self.b # 예측한 직선의 방정식(y^hat, hypothesis(가설))\n",
    "        e = y - pred # 오차\n",
    "        return np.mean(e**2) # Mean Square Error\n",
    "    def fit(self,x,y): # 반복하여 w, b를 찾음\n",
    "        pred = x@self.w + self.b\n",
    "        e = y - pred\n",
    "        dJ_dw = (np.mean(e*(-2*x), axis=0)) # J를 w로 편미분, 0or1에 따라 가로로 세로로\n",
    "        dJ_db = (np.mean(e*(-2), axis=0)) # J를 b로 편미분\n",
    "        self.w = (self.w.T - self.lr*dJ_dw).T # w갱신\n",
    "        self.b = (self.b.T - self.lr*dJ_db) # b갱신\n",
    "    def predict(self, x):\n",
    "        return (x@self.w.T + self.b) # 예측값 반환\n",
    "    def params(self):\n",
    "        return (self.w, self.b) # 우리가 찾고자 하는 파라미터 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcca445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce training data\n",
    "x_train = np.array([[1],[2],[4],[5],[6],[7]])\n",
    "y_train = np.array([[4],[-12],[3],[-11],[-5],[-17]])\n",
    "\n",
    "w_list = [] # weight(기울기) 저장\n",
    "b_list = [] # bias(y절편 저장)\n",
    "c_list = [] # cost 저장\n",
    "\n",
    "ys_list = [] # xs에 대한 예측값 저장을 위한 리스트\n",
    "cl_list = [] # x_train을 위한 예측해 y값을 저장하는 리스트\n",
    "xs = np.array([ # regression 직선을 그리기 위한 x_value 설정\n",
    "    [-3],\n",
    "    [10]\n",
    "])\n",
    "# 모델 학습(training)\n",
    "model = LinearRegression(w=3, b=1, lr=0.001)\n",
    "for i in range(60000): # 반복(epochs) 횟수 지정\n",
    "    w_list.append(model.params()[0]) # 기울기 저장\n",
    "    b_list.append(model.params()[1]) # y절편 저장\n",
    "    c_list.append(model.cost(x_train, y_train)) # cost를 저장\n",
    "    ys_list.append(model.predict(xs).T) # xs에 해당하는 y 예측값 저장\n",
    "    cl_list.append(model.predict(x_train).T) # x_tarin에 해당하는 y값 저장\n",
    "    model.fit(x_train, y_train)\n",
    "print('weight: ' + str(model.params()[0]))\n",
    "print('y_절편: ' + str(model.params()[1]))\n",
    "print('costs: ' + str(model.cost(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c79e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef17fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(x_train, y_train)\n",
    "print(reg.coef_)\n",
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde83b78",
   "metadata": {},
   "source": [
    "### 시각화 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b877a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(0,50,1).tolist()\n",
    "b = np.arange(50,100,5).tolist()\n",
    "c = np.arange(100,12000,200).tolist()\n",
    "# 0~50까지는 1간격, 50~100까지는 5간격, 100이후로는 200간격으로 그림을 그리자\n",
    "p = a + b + c\n",
    "# 리스트를 배열로 반환\n",
    "w = np.array(w_list).flatten() # flatten(펼친다)\n",
    "b = np.array(b_list).flatten() # flatten(펼친다)\n",
    "c = np.array(c_list).flatten() # flatten(펼친다)\n",
    "ys = np.array(ys_list)\n",
    "p = np.array(p)\n",
    "# 첫번째 animation 생성\n",
    "fig = plt.figure(figsize=(10,10)) # figure 생성\n",
    "labelsize_ = 14\n",
    "camera = Camera(fig) # 카메라 생성\n",
    "for i in p:\n",
    "    ax1 = fig.add_subplot(3,2,2)\n",
    "    ax1.plot(w[:i], color='blue', linestyle='dashed', alpha=0.5)\n",
    "    ax1.set_title('w', fontsize=17)\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=labelsize_)\n",
    "    \n",
    "    ax2 = fig.add_subplot(3,2,4)\n",
    "    ax2.plot(w[:i], color='red', linestyle='dashed', alpha=0.5)\n",
    "    ax2.set_title('b', fontsize=17)\n",
    "    ax2.tick_params(axis='both', which='major', labelsize=labelsize_)\n",
    "    \n",
    "    ax3 = fig.add_subplot(3,2,6)\n",
    "    ax3.plot(w[:i], color='black', linestyle='dashed', alpha=0.5)\n",
    "    ax3.set_title('costs', fontsize=17)\n",
    "    ax3.tick_params(axis='both', which='major', labelsize=labelsize_)\n",
    "    ax3.set_xlabel('epochs', fontsize=14, labelpad=10)\n",
    "    ax0 = fig.add_subplot(1,2,1) # fit 그리기\n",
    "    leg = ax0.plot(xs.T.flatten(), ys[i].flatten(), color='r'\n",
    "                   , label=str(i)) # legend 설정, 그림을 그리기 위해 배열 flatten(펼치다)\n",
    "    ax0.scatter(x_train, y_train, color='b', marker='x', s=44)\n",
    "    ax0.legend(leg, [f'eposhs: (i)'], loc='upper right', fontsize=15)\n",
    "    ax0.set_title('Linear fit', fontsize=25)\n",
    "    ax0.tick_params(axis='both', which='major', labelsize=labelsize_)\n",
    "    ax0.set_xlabel('x', fontsize=25, labelpad=10)\n",
    "    ax0.set_ylabel('y', fontsize=25, labelpad=10)\n",
    "    ax0.tick_params(axis='both', which='major', labelsize=labelsize_)\n",
    "    ax0.set_ylim([-20,10])\n",
    "    plt.tight_layout()\n",
    "    camera.snap() # 각각의 프레임 및 반복후에 스냅샷 취함\n",
    "animation = camera.animate(interval=5, repeat=False, repeat_delay=500) # 카메라 애니메이션 생성\n",
    "animation.save('image/SimpleLinReg_1.gif', writer='imagemagick') # 애니메이션 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48261c9",
   "metadata": {},
   "source": [
    "-> pycharm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861e2f73",
   "metadata": {},
   "source": [
    "<img src='./images(1)/20231010_150423_132.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eea007a",
   "metadata": {},
   "source": [
    "$$ J = \\frac{1}{n}\\sum_{i=1}^{n}(y-\\hat{y})^2 \\rightarrow MSE $$\n",
    "$$ \\frac{\\partial J} {\\partial w} = -\\frac{1}{2n}\\sum_{i=1}^{n}(y-\\hat{y})x $$\n",
    "$$ \\frac{\\partial J} {\\partial b} = -\\frac{1}{2n}\\sum_{i=1}^{n}(y-\\hat{y}) $$\n",
    "$$ w \\leftarrow w - \\alpha \\frac{\\partial J} {\\partial w} $$\n",
    "$$ b \\leftarrow b - \\alpha \\frac{\\partial J} {\\partial b} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808bf44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([[1],[2],[4],[5],[6],[7]])\n",
    "y_train = np.array([[4],[-12],[3],[-11],[-5],[-17]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bc3fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ = 3\n",
    "b_ = 1\n",
    "\n",
    "for i in range(50000):\n",
    "    y_hat = w_ * x_train + b_ # 예측값(hypothesis, y_hat), y^ = Wx + b\n",
    "    n = len(x_train) # 데이터 길이\n",
    "    \n",
    "    # 미분\n",
    "    D_m = (-1/n) * sum(x_train * (y_train - y_hat)) # cost(J) 를 W로 편미분(기울기)\n",
    "    D_b = (-1/n) * sum(y_train - y_pred) # cost(J) 를 b로 편미분 (y절편)\n",
    "\n",
    "    # 파라미터 갱신\n",
    "    w_ = w_ - 0.01 * D_m # w갱신\n",
    "    b_ = b_ - 0.01 * D_b # b갱신\n",
    "    \n",
    "    c_ = (1/n) * sum( (y_train - y_hat)**2 ) # cost = MSE\n",
    "    if i%1000==0:\n",
    "        print(w_, b_, c_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f87207",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611dd802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_w(x, y, w_, b_):\n",
    "    y_hat = w_ * x + b_ # 예측값(hypothesis, y_hat), y^ = Wx + b\n",
    "    n = len(x) # 데이터 길이\n",
    "    result = 0\n",
    "    for x_i, y_i, y_hat_i in zip(x, y, y_hat):\n",
    "        result += (y_i- y_hat_i) * x_i\n",
    "    return 1/(2*n)*result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e736a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_b(x, y, w_, b_):\n",
    "    y_hat = w_ * x + b_ # 예측값(hypothesis, y_hat), y^ = Wx + b\n",
    "    n = len(x) # 데이터 길이\n",
    "    result = 0\n",
    "    for y_i, y_hat_i in zip(y, y_hat):\n",
    "        result += (y_i - y_hat_i)\n",
    "    return 1/(2*n)*result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b7a8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(x,y,w_,b_):\n",
    "    y_hat = w_ * x + b_ # 예측값(hypothesis, y_hat), y^ = Wx + b\n",
    "    n = len(x) # 데이터 길이\n",
    "    result = 0\n",
    "    for y_i, y_hat_i in zip(y, y_hat):\n",
    "        result += (y_i - y_hat_i)\n",
    "    return 1/(2*n)*result\n",
    "    c_ = (1/n) * sum( (y_train - y_hat)**2 ) # cost = MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a435935",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ = 3\n",
    "b_ = 1\n",
    "\n",
    "for i in range(50000):\n",
    "    # D_b = (-1/n) * sum(y_train - y_pred) # cost(J) 를 b로 편미분 (y절편)\n",
    "    dJ_dw = grade_w(x_train, y_train, w_, b_)\n",
    "    dJ_db = grade_b(x_train, y_train, w_, b_)\n",
    "    \n",
    "    # 파라미터 갱신\n",
    "    w_ = w_ - 0.01 * D_m # w갱신\n",
    "    b_ = b_ - 0.01 * D_b # b갱신\n",
    "    c_ = cost(x_train, y_train, w_, b_)\n",
    "    \n",
    "    if i%1000==0:\n",
    "        print(w_, b_, c_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f98c0b9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdd90e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple linear regression model:\n",
    "class LinearRegression(object):\n",
    "    def __init__(self,w=1,b=1, lr=0.01):\n",
    "        self.lr=lr\n",
    "        self.w=np.array([[w]])\n",
    "        self.b=np.array([b])\n",
    "\n",
    "    def cost(self,x,y):\n",
    "        pred = x@self.w+self.b  # predicted y-values\n",
    "        e=y-pred             # error term\n",
    "        return np.mean(e**2)  # mean squared error\n",
    "\n",
    "    def fit(self, x,y):\n",
    "        pred = x@self.w+self.b\n",
    "        e=y-pred\n",
    "        dJ_dw=(np.mean(e*(-2*x), axis=0)) # partial derivate of J with respect to w\n",
    "        dJ_db=(np.mean(e*(-2),axis=0)) # partial derivate of J with respect to b\n",
    "        self.w = (self.w.T-self.lr*dJ_dw).T  # update w\n",
    "        self.b = self.b - self.lr*dJ_db    # update b\n",
    "\n",
    "    def predict(self, x):\n",
    "        return (x @ self.w.T + self.b)  # return predicted values\n",
    "\n",
    "    def params(self):\n",
    "        return (self.w,self.b)   # return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111d4a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import celluloid\n",
    "from celluloid import Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57925a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce training data\n",
    "x_train = np.array([[1],[2],[4],[5],[6],[7]])\n",
    "y_train = np.array([[4],[-12],[3],[-11],[-5],[-17]])\n",
    "print('x_train:', x_train,'\\ny_train:', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb15b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce lists where data points are being stored:\n",
    "w_list=[]   # list contains weights\n",
    "b_list=[]   # list contains biases\n",
    "c_list=[]   # list contains costs\n",
    "ys_list=[]  # store arrays of predicted y-values for xs ( -> plot regression line!)\n",
    "cl_list = [] # list contains predicted y-values for x_train ( -> plot connecting lines!)\n",
    "\n",
    "# set x-values for regression line plot\n",
    "xs= np.array([[-3],[10]])\n",
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c848df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model:\n",
    "model=LinearRegression(w=3,b=-1,lr=0.001) # set initial parameters and learning rate\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bca09fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(60000):      # set number of epochs\n",
    "    w_list.append(model.params()[0])    # append weights (=slopes) to list\n",
    "    b_list.append(model.params()[1])    # append biases (=y-intercepts) to list\n",
    "    c_list.append(model.cost(x_train,y_train))  # append costs to list\n",
    "    ys_list.append(model.predict(xs).T)     # append pairs of predicted y-values for xs\n",
    "    cl_list.append(model.predict(x_train).T) # append predicted y-values for x_train to list\n",
    "    model.fit(x_train, y_train) # fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84adcb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print parameters and costs after all epochs\n",
    "print(\"weight: \" + str( model.params()[0]) )\n",
    "print(\"y-intercept: \" + str( model.params()[1]) )\n",
    "print(\"costs: \"+ str(model.cost(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a59a609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which epochs/data points to plot\n",
    "a = np.arange(0, 50, 1).tolist()\n",
    "b = np.arange(50, 100, 5).tolist()\n",
    "c = np.arange(100, 12000, 200).tolist()\n",
    "p = a + b + c  # points we want to plot\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ecb7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn lists into arrays\n",
    "w = np.array(w_list).flatten()\n",
    "b = np.array(b_list).flatten()\n",
    "c = np.array(c_list).flatten()\n",
    "ys = np.array(ys_list)\n",
    "p = np.array(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f1bac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create first animation:\n",
    "fig ,axs = plt.subplots(2,2,figsize=(10, 10))  # create figure\n",
    "#labelsize_ = 14\n",
    "camera = Camera(fig)  # create camera\n",
    "print(len(p))\n",
    "for idx , i in enumerate(p):\n",
    "    if idx%7==0:\n",
    "        print(\"진행중:\",idx)\n",
    "        # 서브플롯 업데이트\n",
    "        axs[0, 0].plot(xs.T.flatten(), ys[i].flatten(), color='r')\n",
    "        axs[0, 0].scatter(x_train, y_train, color='b', marker='x', s=44)\n",
    "        axs[0, 0].set_title(f\"선형 피팅 - Epoch: {i}\")\n",
    "\n",
    "        axs[0, 1].plot(w[:i + 1], color='blue', linestyle=\"dashed\", alpha=0.5)\n",
    "        axs[0, 1].set_title(\"w\")\n",
    "\n",
    "        axs[1, 0].plot(b[:i + 1], color='red', linestyle=\"dashed\", alpha=0.5)\n",
    "        axs[1, 0].set_title(\"b\")\n",
    "\n",
    "        axs[1, 1].plot(c[:i + 1], color='black', linestyle=\"dashed\")\n",
    "        axs[1, 1].set_title(\"비용\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        camera.snap()\n",
    "\n",
    "animation = camera.animate(interval=5,\n",
    "                           repeat=False, repeat_delay=500)  # create animation\n",
    "animation.save('media/SimpleLinReg_1.gif', writer='imagemagick')  # save animation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f7426f",
   "metadata": {},
   "source": [
    "# 𝑓𝑒𝑎𝑡𝑢𝑟𝑒가 하나일 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b270e3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ = 3\n",
    "b_ = 1\n",
    "\n",
    "for i in range(50000):\n",
    "    y_hat = w_ * x_train + b_ # 예측값(hypothesis, y_hat), y^ = Wx + b\n",
    "    n = len(x_train) # 데이터 길이\n",
    "    \n",
    "    # 미분\n",
    "    D_m = -1/(2*n) * sum(x_train * (y_train - y_hat)) # cost(J) 를 W로 편미분(기울기)\n",
    "    D_b = -1/(2*n) * sum(y_train - y_hat) # cost(J) 를 b로 편미분 (y절편)\n",
    "\n",
    "    # 파라미터 갱신\n",
    "    w_ = w_ - 0.01 * D_m # w갱신\n",
    "    b_ = b_ - 0.01 * D_b # b갱신\n",
    "    \n",
    "    c_ = (1/n) * sum( (y_train - y_hat)**2 ) # cost = MSE\n",
    "    if i%1000==0:\n",
    "        print(w_, b_, c_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9ae1ea",
   "metadata": {},
   "source": [
    "$$ J = \\frac{1}{n}\\sum_{i=1}^{n}(y-\\hat{y})^2 \\rightarrow MSE $$\n",
    "$$ \\frac{\\partial J} {\\partial w} = -\\frac{1}{2n}\\sum_{i=1}^{n}(y-\\hat{y})x $$\n",
    "$$ \\frac{\\partial J} {\\partial b} = -\\frac{1}{2n}\\sum_{i=1}^{n}(y-\\hat{y}) $$\n",
    "$$ w \\leftarrow w - \\alpha \\frac{\\partial J} {\\partial w} $$\n",
    "$$ b \\leftarrow b - \\alpha \\frac{\\partial J} {\\partial b} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da05d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([[1],[2],[4],[5],[6],[7]])\n",
    "print(x_train.shape)\n",
    "\n",
    "y_train = np.array([[4],[-12],[3],[-11],[-5],[-17]])\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8cad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ = 3\n",
    "b_ = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a45976f",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial J} {\\partial w} = -\\frac{1}{2n}\\sum_{i=1}^{n}(y-\\hat{y})x $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09982c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_w(x, y, w_, b_):\n",
    "    y_hat = w_ * x + b_ # 예측값(hypothesis, y_hat), y^ = Wx + b\n",
    "    n = len(x) # 데이터 길이\n",
    "    result = 0\n",
    "    for x_i, y_i, y_hat_i in zip(x, y, y_hat):\n",
    "        result += (y_i- y_hat_i) * x_i\n",
    "    return -1/(2*n)*result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caac0b7",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial J} {\\partial b} = -\\frac{1}{2n}\\sum_{i=1}^{n}(y-\\hat{y}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f0e254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_b(x, y, w_, b_):\n",
    "    y_hat = w_ * x + b_ # 예측값(hypothesis, y_hat), y^ = Wx + b\n",
    "    n = len(x) # 데이터 길이\n",
    "    result = 0\n",
    "    for y_i, y_hat_i in zip(y, y_hat):\n",
    "        result += (y_i - y_hat_i)\n",
    "    return -1/(2*n)*result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa2c30e",
   "metadata": {},
   "source": [
    "$$ J = \\frac{1}{n}\\sum_{i=1}^{n}(y-\\hat{y})^2 \\rightarrow MSE $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b830627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(x,y,w_,b_):\n",
    "    y_hat = w_ * x + b_ # 예측값(hypothesis, y_hat), y^ = Wx + b\n",
    "    n = len(x) # 데이터 길이\n",
    "    result = 0\n",
    "    for y_i, y_hat_i in zip(y, y_hat):\n",
    "         result += (y_i - y_hat_i)**2\n",
    "    return (1/n)*result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cef6118",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w_ = 3\n",
    "b_ = 1\n",
    "\n",
    "for i in range(50000):\n",
    "    # D_b = (-1/n) * sum(y_train - y_pred) # cost(J) 를 b로 편미분 (y절편)\n",
    "    dJ_dw = grad_w(x_train, y_train, w_, b_)\n",
    "    dJ_db = grad_b(x_train, y_train, w_, b_)\n",
    "    \n",
    "    # 파라미터 갱신\n",
    "    w_ = w_ - 0.01 * dJ_dw # w갱신\n",
    "    b_ = b_ - 0.01 * dJ_db # b갱신\n",
    "    c_ = cost(x_train, y_train, w_, b_)\n",
    "    \n",
    "    if i%1000==0:\n",
    "        print(w_, b_, c_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644b01b0",
   "metadata": {},
   "source": [
    "# 𝑓𝑒𝑎𝑡𝑢𝑟𝑒가 여러 개이며  𝑡𝑟𝑎𝑖𝑛𝑖𝑛𝑔𝑑𝑎𝑡𝑎(6쌍)\n",
    "$feature$가 하나일 때는 그나마 고차원 생각을 하지 않아도 되는데 $feature$가 여러 개이고 $training data(6쌍)$이므로 행렬의 사고를 가져야한다.\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>feature 1</th>\n",
    "        <th>feature 2</th>\n",
    "        <th> label </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>2</td>\n",
    "        <td>3</td>\n",
    "        <td>4</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>3</td>\n",
    "        <td>2</td>\n",
    "        <td>-12</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>1</td>\n",
    "        <td>2</td>\n",
    "        <td>3</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>-1</td>\n",
    "        <td>-2</td>\n",
    "        <td>-11</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>2</td>\n",
    "        <td>3</td>\n",
    "        <td>-5</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>3</td>\n",
    "        <td>4</td>\n",
    "        <td>-7</td>\n",
    "    </tr>\n",
    "<table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092b15c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w_1 = 3\n",
    "w_2 = 2\n",
    "b_ = -1\n",
    "# 초기값 weight(w1, w2, bias(b)의 초기값) learing=> hyper parameter\n",
    "alpha = 0.01 # 학습률, learing_rate, 크면 빠르게 수렴하지만 global mimimun에 도달하지 않을 수 있어요.)\n",
    "\n",
    "for i in range(100000):\n",
    "    y_hat = w_1 * x_train.T[0] + w_2 * x_train.T[1] + b_ # 예측값(hypothesis, y_hat)\n",
    "    if i % 10000 == 0:\n",
    "        print('y_hat', y_hat.shape, 'y_train:', y_train.shape) # shape이 일치하지 않음(1차원 벡터, 2차원 행렬)\n",
    "        n = len(x_train)\n",
    "        \n",
    "    # 미분\n",
    "    DJ_dm1 = -1/n * sum(x_train.T[0] * (y_train.ravel() - y_hat)) # y_train.ravel()=> 2차원을 1차원으로 변환\n",
    "    DJ_dm2 = -1/n * sum(x_train.T[1] * (y_train.ravel() - y_hat)) # cost(J) 를 W로 편미분(기울기)\n",
    "    D_b = -1/n * sum(y_train.ravel() - y_hat) # cost(J) 를 b로 편미분 (y절편)\n",
    "    \n",
    "    # 파라미터 갱신\n",
    "    w_1 = w_1 - alpha * DJ_dm1 # w갱신\n",
    "    w_2 = w_2 - alpha * DJ_dm2 # w갱신\n",
    "    b_ = b_ - alpha * D_b # b갱신\n",
    "    \n",
    "    # 비용 함수 계산 수정\n",
    "    c_ = (1/n) * sum( (y_train.ravel() - y_hat)**2 )\n",
    "    \n",
    "    if i%10000 == 0:\n",
    "        print('w1:',w_1,'w2:', w_2,'b:', b_,'cost:', c_, '오차범위:',abs(c_-0)<0.001)\n",
    "        print(\"=========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d379be6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 검증\n",
    "[(i[0] * 2.813459268004652 + i[1] * -1.455135773317597 + -9.066115702479113) for i, j in zip(x_train, y_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4d4b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = 1.5000000000000457\n",
    "w2 = 0.4999999999999684\n",
    "b = 1.9999999999999396\n",
    "for i, j in zip(x_train, y_train):\n",
    "    print(i[0]*w1 + i[1]*w2 + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e697eb0c",
   "metadata": {},
   "source": [
    "$$ J = \\frac{1}{n}\\sum_{i=1}^{n}(y-\\hat{y})^2 \\rightarrow MSE $$\n",
    "$$ \\frac{\\partial J} {\\partial w} = -\\frac{1}{2n}\\sum_{i=1}^{n}(y-\\hat{y})x $$\n",
    "$$ \\frac{\\partial J} {\\partial b} = -\\frac{1}{2n}\\sum_{i=1}^{n}(y-\\hat{y}) $$\n",
    "$$ w \\leftarrow w - \\alpha \\frac{\\partial J} {\\partial w} $$\n",
    "$$ b \\leftarrow b - \\alpha \\frac{\\partial J} {\\partial b} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9038bcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([[1,1],[2,2],[3,3],[4,4],[5,5],[6,6]])\n",
    "print(x_train.shape) # w1=1, w2=1, b=2\n",
    "\n",
    "y_train = np.array([[4],[6],[8],[10],[12],[14]])\n",
    "print(y_train.shape) # label(정답)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc812b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_1 = 3\n",
    "w_2 = 100\n",
    "b_ = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e00b5a",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial J} {\\partial w_{1}} = -\\frac{1}{2n}\\sum_{i=1}^{n}(y-\\hat{y})x_{1} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e2bad2",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial J} {\\partial w_{2}} = -\\frac{1}{2n}\\sum_{i=1}^{n}(y-\\hat{y})x_{2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1af58eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_w1(x, y, w1_,w2_, b_):\n",
    "    y_hat = w1_ * x[0] + w2_ * x[1] + b_ # 예측값(hypothesis, y_hat), y^ = Wx + b\n",
    "    n = len(x) # 데이터 길이\n",
    "    result = 0\n",
    "    for x_i, y_i, y_hat_i in zip(x, y, y_hat):\n",
    "        result += (y_i- y_hat_i) * x_i\n",
    "    return -1/(2*n)*result\n",
    "\n",
    "def grad_w2(x, y, w1_,w2_, b_):\n",
    "    y_hat = w1_ * x[0] + w2_ * x[1] + b_ # 예측값(hypothesis, y_hat), y^ = Wx + b\n",
    "    n = len(x) # 데이터 길이\n",
    "    result = 0\n",
    "    for x_i, y_i, y_hat_i in zip(x, y, y_hat):\n",
    "        result += (y_i- y_hat_i) * x_i\n",
    "    return -1/(2*n)*result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84203ff",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial J} {\\partial b} = -\\frac{1}{2n}\\sum_{i=1}^{n}(y-\\hat{y}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f619a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_b(x, y, w1_,w2_, b_):\n",
    "    y_hat = w1_ * x[0] + w2_ * x[1] + b_ # 예측값(hypothesis, y_hat), y^ = Wx + b\n",
    "    n = len(x) # 데이터 길이\n",
    "    result = 0\n",
    "    for y_i, y_hat_i in zip(y, y_hat):\n",
    "        result += (y_i - y_hat_i)\n",
    "    return -1/(2*n)*result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237b9a6c",
   "metadata": {},
   "source": [
    "$$ \\hat{y} = w_{1}x_{1} + w_{2}x_{2} + b $$\n",
    "$$ J = \\frac{1}{n}\\sum_{i=1}^{n}(y-\\hat{y})^2 \\rightarrow MSE $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75de58a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(x,y,w1_,w2_,b_):\n",
    "    y_hat = w1_ * x[0] + w2_ * x[1] + b_ # 예측값(hypothesis, y_hat), y^ = Wx + b\n",
    "    n = len(x) # 데이터 길이\n",
    "    result = 0\n",
    "    for y_i, y_hat_i in zip(y, y_hat):\n",
    "         result += (y_i - y_hat_i)**2\n",
    "    return (1/n)*result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e041984d",
   "metadata": {},
   "source": [
    "$$ w_{1} \\leftarrow w_{1} - \\alpha \\frac{\\partial J} {\\partial w_{1}} $$\n",
    "$$ w_{2} \\leftarrow w_{2} - \\alpha \\frac{\\partial J} {\\partial w_{2}} $$\n",
    "$$ b \\leftarrow b - \\alpha \\frac{\\partial J} {\\partial b} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97464b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_ = 3\n",
    "w2_ = 100\n",
    "b_ = 1\n",
    "\n",
    "for i in range(50000):\n",
    "    # D_b = (-1/n) * sum(y_train - y_pred) # cost(J) 를 b로 편미분 (y절편)\n",
    "    dJ_dw1 = grad_w1(x_train, y_train, w1_,w2_, b_)\n",
    "    dJ_dw2 = grad_w1(x_train, y_train, w1_,w2_, b_)\n",
    "    dJ_db = grad_b(x_train, y_train, w1_,w2_, b_)\n",
    "    \n",
    "    # 파라미터 갱신\n",
    "    w1_ = w1_ - 0.01 * dJ_dw1 # w갱신\n",
    "    w2_ = w2_ - 0.01 * dJ_dw1 # w갱신\n",
    "    b_ = b_ - 0.01 * dJ_db # b갱신\n",
    "    c_ = cost(x_train, y_train, w1_,w2_, b_)\n",
    "    \n",
    "    if i%1000==0:\n",
    "        print(w1_,w2_, b_, c_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a04c7db",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e60848a",
   "metadata": {},
   "source": [
    "# logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e922af1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons # 머신러닝 라이브러리\n",
    "import matplotlib.pyplot as plt # 그림그리기\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f42f910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid (z): # (𝑤⋅𝑥+𝑏)\n",
    "    return 1.0/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f18467",
   "metadata": {},
   "source": [
    "## Hypothesis (가설)\n",
    "$$ \\frac{1}{1+ e+{-(w \\cdot x+b})} $$\n",
    "\n",
    "## logistic regression의 cost 함수 = \n",
    "$$ J(W,b) = \\frac{1}{m}\\sum_{i=1}^{m}L(\\widehat{y}^{(i)}, y^{(i)}) =\n",
    "    -\\frac{1}{m}\\sum_{i=1}^{m}[y^{(i)}log(\\widehat{y}^{(i)}+(1-y^{(i)})log(1-\\widehat{y}^{(i)})]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb04182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y, y_hat): # Cross Entropy\n",
    "    loss = -np.mean(y*(np.log(y_hat)) - (1-y)*np.log(1-y_hat))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27c7ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients(X, y, y_hat):\n",
    "    # X ---> 입력\n",
    "    # y ---> 정답(target / label)\n",
    "    # y_hat ---> 가설(모델의 출력, hypothesis/예측치(prediction/추정))\n",
    "    # w ---> weigth(파라미터, theta / 우리가 구하고자 하는 값)\n",
    "    # b ---> bias (파라미터, theta 0 )\n",
    "    \n",
    "    # m ---> 학습(trainging) 데이터의 갯수\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # Cost(Loss)를 weight로 미분함\n",
    "    dw = (1/m)*np.dot(X.T, (y_hat - y))\n",
    "    \n",
    "    # Cost(Loss)를 bias로 미분함 \n",
    "    db = (1/m)*np.sum((y_hat - y))\n",
    "    \n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addf2215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(X, w, b):\n",
    "    # X = 입력\n",
    "    # w = 가중치\n",
    "    # b = bais\n",
    "    \n",
    "    # 직선은  = mx + c\n",
    "    # 그래서 직선의 방정식 mx + c = w.X + b    [.(닷)은 곱한다는 뜻) ]\n",
    "    # m과 c를 풀어라\n",
    "    x1 = [min(X[:, 0]), max(X[:, 0])] # X[:0] X의 모든 행을 가져오고 0열 선택\n",
    "    m = -w[0]/w[1]\n",
    "    c = -b/w[1]\n",
    "    x2 = m*x1 + c\n",
    "    \n",
    "    # 그림 그리기\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"g^\")\n",
    "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\")\n",
    "    plt.xlim([-2, 2]) # x 구간 지정\n",
    "    plt.ylim([0, 2.2]) # ylimit (y 구간지정)\n",
    "    plt.xlabel(\"feature 1\")\n",
    "    plt.ylabel(\"feature 2\")\n",
    "    plt.title('Decision Boundary')\n",
    "    plt.plot(x1, x2, 'y-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e131fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    # X <= 입력\n",
    "    # m <= training 개수\n",
    "    # n <= feature 의 갯수 (weight와 내적하는 것)\n",
    "    m, n = X.shape # (m,n) m행 n열\n",
    "    # X행렬의 모든 n개 feature들을 정규화함\n",
    "    for i in range(n):\n",
    "        X = (X - X.mean(axis=0))/X.std(axis=0) \n",
    "        # 어제 했던 수식(데이터와 평균의 차이를) 표준편차(stanard deviation)으로 나눔\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd03cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 함수\n",
    "## 이 함수에서 gradient descent를 반복하여 학습을 하고 weight와 bias를 구함\n",
    "def train(X, y, bs, epochs, lr): \n",
    "    # X <- 입력\n",
    "    # y <- true / target\n",
    "    # epoch는 반복횟수\n",
    "    # lr = learning rate(학습율)\n",
    "    \n",
    "    # m <- 학습데이터의 수\n",
    "    # n <- feature의 수\n",
    "    \n",
    "    m, n = X.shape\n",
    "    # wieght와 bias 초기화\n",
    "    w = np.zeros((n, 1))\n",
    "    b = 0\n",
    "    # y를 reshape함(형태를 맞춤)\n",
    "    y = y.reshape(m, 1)\n",
    "    # 입력 데이터 normalize\n",
    "    x = normalize(X)\n",
    "    # LOSS를 저장하기 위한 빈 LIST 생성\n",
    "    losses = []\n",
    "    # 학습\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((m-1)//bs + 1):\n",
    "            # batch 정의, SGD(Stocastric(통계적0), Gradient Descent)\n",
    "            start_i = i*bs # bs(배치 사이즈)\n",
    "            end_i = start_i + bs\n",
    "            xb = X[start_i:end_i]\n",
    "            yb = y[start_i:end_i]\n",
    "            \n",
    "            # hypothesis / 예측 계산\n",
    "            y_hat = sigmoid(np.dot(xb, w) + b)\n",
    "            # loss를 파라미터로 미분\n",
    "            dw, db = gradients(xb, yb, y_hat)\n",
    "            # 파라미터 갱신\n",
    "            w -= lr*dw\n",
    "            b -= lr*db\n",
    "        l = loss(y, sigmoid(np.dot(X, w) + b))\n",
    "        losses.append(l)\n",
    "    # weight와 bias, loss 반환\n",
    "    return w, b, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fcb713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 함수\n",
    "def predict(X):\n",
    "    # X <- 입력\n",
    "    # 입력 데이터 normalize\n",
    "    x = normalize(X)\n",
    "    \n",
    "    # 예측 / 추정치 / y_hat 계산\n",
    "    preds = sigmoid(np.dot(X, w) + b)\n",
    "    # 예측 데이터 저장 리스트 생성\n",
    "    pred_class = []\n",
    "    # y_hat >= 0.5 -> 1로 결과를 출력\n",
    "    # y_hat < 0.5 -> 0으로 결과를 출력\n",
    "    pred_class = [1 if i > 0.5 else 0 for i in preds]\n",
    "    return np.array(pre_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccf618e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 학습\n",
    "X, y = make_moons(n_samples=100, noise=0.24)\n",
    "w, b, l = train(X, y, bs=100, epochs=1000, lr=0.01)\n",
    "# 그림 그리기\n",
    "plot_decision_boundary(X,w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae94179",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = np.array(X[:10][:,0]) # y_hat이라 가정합니다.\n",
    "print(np.shape(X_))\n",
    "\n",
    "y_ = np.array(y[:10])\n",
    "print(np.shape(y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cb3cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제) \n",
    "y_hat = np.array(X[:10][:,0]) # y_hat이라 가정합니다.\n",
    "np.shape(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751671ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_true = [np.random.randint(10) for i in range(10)]\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e621a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true[0]* np.log(np.abs(y_hat[0])) + (1-y_true[0])*np.log(np.abs(1-y_hat[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7cccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = 0\n",
    "for i, j in zip(y_true, y_hat):\n",
    "    cross_entropy += i* np.log(np.abs(j)) + (1-i)*np.log(np.abs(1-j)) \n",
    "count = len(y_true)\n",
    "-cross_entropy / count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cf19a6",
   "metadata": {},
   "source": [
    "## 손실(Loss) / Cost(비용) 함수\n",
    "## logistic regression의 cost 함수 = \n",
    "$$ J(W,b) = \\frac{1}{m}\\sum_{i=1}^{m}L(\\widehat{y}^{(i)}, y^{(i)}) =\n",
    "    -\\frac{1}{m}\\sum_{i=1}^{m}[y^{(i)}log(\\widehat{y}^{(i)}+(1-y^{(i)})log(1-\\widehat{y}^{(i)})]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5d7207",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=300, noise=0.24)\n",
    "print('X:', np.shape(X)) # X데이터 (100행 2열 행렬)\n",
    "print('y:', np.shape(X)) # X데이터 (100행 벡터)\n",
    "bs = 15\n",
    "m = 20\n",
    "for epoch in range(10):\n",
    "    for i in range((m-1)//bs+1):\n",
    "        # batch 정의, SGD(Stocastric(통계적0) Gradient Descent)\n",
    "        start_i = i*bs # bs(배치 사이즈)\n",
    "        end_i = start_i + bs\n",
    "        xb = X[start_i:end_i]\n",
    "        yb = y[start_i:end_i]\n",
    "        print('start: ', start_i, ', end: ', end_i, ', epoch: ', epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6771835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(-3,3,0.01)\n",
    "y = sigmoid(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90c69f3",
   "metadata": {},
   "source": [
    "#### 미분의 정의 remind\n",
    "$$ \\lim_{h\\rightarrow 0} \\frac{f(x+h)-f(x)}{h} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3595fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(f, x):\n",
    "    h = 0.00001\n",
    "    return (f(x+h)-f(x))/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997031ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "derivated = derivative(sigmoid, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d7f10a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b2f56b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(X, derivated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567909e2",
   "metadata": {},
   "source": [
    "##  Hessian 행렬\n",
    "$$   \\begin{bmatrix}\n",
    " \\frac{\\partial^{2}f}{\\partial x_{1}^2} &  \\frac{\\partial^{2}f}{\\partial x_{1} \\partial x_{2} }  & \\cdot  \\cdot \\cdot  &  \\frac{\\partial^{2}f}{\\partial x_{1} \\partial x_{n} }    \\\\\n",
    "\\frac{\\partial^{2}f}{\\partial x_{2} \\partial x_{1}} &\n",
    "\\frac{\\partial^{2}f}{\\partial x_{1}^2}  & \\cdot  \\cdot \\cdot  &  \n",
    "  \\frac{\\partial^{2}f}{\\partial x_{2}\\partial x_{n}}   \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial^{2}f}{\\partial x_{n} \\partial x_{1} } &  \\frac{\\partial^{2}f}{\\partial x_{n} \\partial x_{2} }  & \\cdot  \\cdot \\cdot  &  \\frac{\\partial^{2}f}{\\partial x_{n}^{2}}   \n",
    "\\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88246855",
   "metadata": {},
   "source": [
    "<a href=\"https://angeloyeo.github.io/2020/06/17/Hessian.html\">헤시안 행렬의 기하학 의미</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a566c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import symbols, Matrix, Function, simplify, exp, hessian, solve, init_printing\n",
    "x1, x2 = symbols('x1 x2')\n",
    "f, g, h = symbols('f g h', cls=Function)\n",
    "\n",
    "X = Matrix([x1, x2])\n",
    "f = Matrix([-x1*x2*exp(-(x1**2 + x2**2)/2)])\n",
    "h = 2*x1 + 3* x2\n",
    "g = x1**2 + x2**2-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3b26a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradf = simplify(f.jacobian(X))\n",
    "gradf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8a6045",
   "metadata": {},
   "outputs": [],
   "source": [
    "hessian = simplify(hessian(f, X)) # hessian(대칭)\n",
    "hessian"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
