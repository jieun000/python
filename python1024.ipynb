{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b22aeb92",
   "metadata": {},
   "source": [
    "<img src=\"images/a.webp\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f60763",
   "metadata": {},
   "source": [
    "<img src=\"images/filter1.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bd9371",
   "metadata": {},
   "source": [
    "<img src=\"images/filter2.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af10df2",
   "metadata": {},
   "source": [
    "<img src=\"images/filter3.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36adf413",
   "metadata": {},
   "source": [
    "<img src=\"images/filter4.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2321ae",
   "metadata": {},
   "source": [
    "<img src=\"images/filter5.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04472730",
   "metadata": {},
   "source": [
    "##### 원이미지와 kernel(filter)를 convolution 하려는데 가상에는 데이터가 부족해서 0을 추가해야 하므로 이것을 zeros padding이라함.\n",
    "- convolution: 이동하면서 내적함\n",
    "\n",
    "0패딩 말고 인접한 데이터를 padding 할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41e4173",
   "metadata": {},
   "source": [
    "<img src=\"images/convolution.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b9777d",
   "metadata": {},
   "source": [
    "<img src=\"images/convolution.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0740ff27",
   "metadata": {},
   "source": [
    "<img src=\"images/equation1.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956ebaba",
   "metadata": {},
   "source": [
    "<img src=\"images/equation2.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cfa7a6",
   "metadata": {},
   "source": [
    "<img src=\"images/20231023_130002_458.jpg\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73a18aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 5), (3, 3))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "image = np.array([[-1,1,0,1,0],[-1,3,1,2,5],[-1,2,5,6,7],[8,-1,1,0,1],[-1,0,0,1,0]])\n",
    "filtered  = np.array([[-1,0,1],[0,1,0],[0,1,1]])\n",
    "# 2개의 신호를 convolution하세요\n",
    "image.shape, filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7601578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4, -1,  1, -3,  2],\n",
       "       [-4, -3, -2,  1, 12],\n",
       "       [-1, 11,  8,  9, 14],\n",
       "       [ 7, -1,  7, 11, 15],\n",
       "       [ 7,  7,  0,  2,  1]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이것을 노가다로 만들어볼 것\n",
    "from scipy.signal import convolve2d\n",
    "flt_img = convolve2d(image, filtered, mode='same')\n",
    "flt_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f459e4",
   "metadata": {},
   "source": [
    "<a href=\"https://m.blog.naver.com/wideeyed/221665256911\">[Numpy] 1차원 또는 2차원 패딩</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a70340f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 5), (3, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "image = np.array([[-1,1,0,1,0],[-1,3,1,2,5],[-1,2,5,6,7],[8,-1,1,0,1],[-1,0,0,1,0]])\n",
    "filtered  = np.array([[-1,0,1],[0,1,0],[0,1,1]])\n",
    "# 2개의 신호를 convolution하세요\n",
    "image.shape, filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38d60651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, -1,  1,  0,  1,  0,  0],\n",
       "       [ 0, -1,  3,  1,  2,  5,  0],\n",
       "       [ 0, -1,  2,  5,  6,  7,  0],\n",
       "       [ 0,  8, -1,  1,  0,  1,  0],\n",
       "       [ 0, -1,  0,  0,  1,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상하좌우 모두 2개 행/열 0으로 패딩합니다\n",
    "np.pad(image, ((1,1),(1,1)), 'constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e117bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, -1,  1,  0,  1,  0,  0],\n",
       "       [ 0, -1,  3,  1,  2,  5,  0],\n",
       "       [ 0, -1,  2,  5,  6,  7,  0],\n",
       "       [ 0,  8, -1,  1,  0,  1,  0],\n",
       "       [ 0, -1,  0,  0,  1,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_image = []\n",
    "padded_zero = np.array([0 for i in range(5)]) # 5개를 0으로 만들다\n",
    "padded_image.append(padded_zero) # 첫번째 행에 0을 추가\n",
    "for i in image:\n",
    "    padded_image.append(i) # image를 다 추가\n",
    "padded_image.append(padded_zero) # 마지막 행에 0을 추가\n",
    "transposed_first = np.array(padded_image)\n",
    "padded_zero = np.array([0 for i in range(7)]) # 7개를 0으로 만든다.\n",
    "copyed = np.array([padded_zero, *transposed_first.T, padded_zero]) # *transposed_first.T 세로에 0 추가\n",
    "padded_image = copyed.T # 다시 원래대로 돌리기 위해 transpose 해서 복원\n",
    "padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2f5c385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 9, 9, -2],\n",
       " [5, 11, 4, 5, -7],\n",
       " [3, 12, 5, 6, 1],\n",
       " [8, 15, 11, 3, 1],\n",
       " [5, 11, 6, -5, 0]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolved = []\n",
    "for j in range(5):\n",
    "    convolved.append([sum(sum(np.multiply(padded_image[i:i+3, j:j+3], filtered))) for i in range(5) ])\n",
    "convolved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9825e73",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "670686ac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f20dcde4",
   "metadata": {},
   "source": [
    "<img src=\"images/공식.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca6d46f",
   "metadata": {},
   "source": [
    "<img src=\"images/filter6.jpg\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a266e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99db7758",
   "metadata": {},
   "source": [
    "<img src=\"images/filter7.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc0b66d",
   "metadata": {},
   "source": [
    "<a href=\"https://velog.io/@se0yeon00/%EC%98%81%EC%83%81%EC%8B%A0%ED%98%B8%EC%B2%98%EB%A6%AC\">영상 신호 처리 필터</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dedd7ee",
   "metadata": {},
   "source": [
    "<a href=\"https://programmingfbf7290.tistory.com/entry/%EC%A3%BC%ED%8C%8C%EC%88%98-%EC%98%81%EC%97%AD-%EC%98%81%EC%83%81-%ED%95%84%ED%84%B0%EA%B0%80%EC%9A%B0%EC%8B%9C%EC%95%88-%EC%A3%BC%ED%8C%8C%EC%88%98-%ED%95%84%ED%84%B0\">영상 신호 처리 가우시안</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca59175e",
   "metadata": {},
   "source": [
    "<a href=\"https://junstar92.tistory.com/405\">영상 신호 처리 가우시안</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e31a9c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e27869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepocessing(image):\n",
    "    image = cv2.imread(image)\n",
    "    image = cv2.cvtColor(src=image, code=cv2.COLOR_BGR2GRAY)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cac4c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve2D(image, kernel, padding=0, strides=1):\n",
    "    # kernel = fliter, stride=> 몇칸씩 이동하면서 convolution할지 결정\n",
    "    kernel = np.flipud(np.fliplr(kernel)) # left right(수평뒤집기), up -> down(수직뒤집기, )\n",
    "    # 이미지와 kernel의 shape을 구함\n",
    "    xKernelShape = kernel.shape[0]\n",
    "    yKernelShape = kernel.shape[1]\n",
    "    xImageShape = image.shape[0]\n",
    "    yImageShape = image.shape[1]\n",
    "    # 각각의 출력 차원을 크기 공식을 적용하여 구할 수 있음\n",
    "    xOutput = int(((xImageShape - xKernelShape + 2*padding) / strides) + 1) # 위의 공식\n",
    "    yOutput = int(((yImageShape - yKernelShape + 2*padding) / strides) + 1)\n",
    "    output = np.zeros((xOutput, yOutput))\n",
    "    if padding != 0:\n",
    "        imagePadded = np.zeros((image.shape[0] + padding*2, image.shape[1] + padding*2))\n",
    "        # padded 이미지의 내부는 실제 이미지로 대체함 (slicing 사용하여)\n",
    "        imagePadded[int(padding):int(-1*padding), int(padding):int(-1*padding)] = image\n",
    "    else: # padding이 없다면\n",
    "        imagepadded = image\n",
    "    for y in range(image.shape[1]): # 반복하면서 이미지의 크기보다\n",
    "        if y > image.shape[1] - yKernelShape: break\n",
    "        if y % strides == 0: # 특정 stride만큼 내려갈 때만 convolution함\n",
    "            for x in range(image.shape[0]):\n",
    "                # 커널의 경계를 벗어나면 다음 행으로 이동\n",
    "                if x > image.shape[0] - xKernelShape: break\n",
    "                try:\n",
    "                    if x % strides == 0: # x의 값이 strides의 배수가 될 때만\n",
    "                        # 특정 stride로 이동할 때만 convolution함\n",
    "                        output[x, y] = (kernel * imagePadded[x:x+xKernelShape, y:y+yKernelShape]).sum()\n",
    "                except:\n",
    "                    break\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68eac1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = np.array([[1/16,1/8,1/16], [1/8,1/4,1/8], [1/16, 1/8, 1/16]])\n",
    "\n",
    "image = prepocessing('images/lenna.bmp')\n",
    "print(image.shape)\n",
    "output = convolve2D(image, kernel, padding=2)\n",
    "cv2.imwrite('2Dconvolved.jpg', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cafae49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]])\n",
    "\n",
    "image = prepocessing('images/lenna.bmp')\n",
    "print(image.shape)\n",
    "output = convolve2D(image, kernel, padding=2)\n",
    "cv2.imwrite('2Dconvolved.jpg', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "603cdaf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = np.array([[-1,-1,-1,-1,-1],[-1,-1,-1,-1,-1],[-1,-1,24,-1,-1],\n",
    "                   [-1,-1,-1,-1,-1],[-1,-1,-1,-1,-1]])\n",
    "\n",
    "image = prepocessing('images/lenna.bmp')\n",
    "print(image.shape)\n",
    "output = convolve2D(image, kernel, padding=2)\n",
    "cv2.imwrite('2Dconvolved5x.jpg', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0753001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n"
     ]
    }
   ],
   "source": [
    "kernel_blur3 = np.array([[1/16,1/8,1/16], [1/8,1/4,1/8], [1/16, 1/8, 1/16]])\n",
    "kernel_3x = np.array([[-1,-1,-1,-1,-1],[-1,-1,-1,-1,-1],[-1,-1,24,-1,-1],\n",
    "                   ])\n",
    "kernel_5x = np.array([[-1,-1,-1,-1,-1],[-1,-1,-1,-1,-1],[-1,-1,24,-1,-1],\n",
    "                   [-1,-1,-1,-1,-1],[-1,-1,-1,-1,-1]])\n",
    "kernel_7x = np.array([[-1,-1,-1,-1,-1],[-1,-1,-1,-1,-1],[-1,-1,24,-1,-1],\n",
    "                   [-1,-1,-1,-1,-1],[-1,-1,-1,-1,-1],\n",
    "                   [-1,-1,-1,-1,-1],[-1,-1,-1,-1,-1]])\n",
    "gaussian_filter_5x5 = np.array([\n",
    "    [1/256, 4/256, 6/256, 4/256, 1/256],\n",
    "    [4/256, 16/256, 24/256, 16/256, 4/256],\n",
    "    [6/256, 24/256, 36/256, 24/256, 6/256],\n",
    "    [4/256, 16/256, 24/256, 16/256, 4/256],\n",
    "    [1/256, 4/256, 6/256, 4/256, 1/256]\n",
    "])\n",
    "\n",
    "list_kernel = [kernel_3x, kernel_5x ,kernel_7x, kernel_blur3, gaussian_filter_5x5]\n",
    "image = prepocessing('images/lenna.bmp')\n",
    "print(image.shape)\n",
    "for idx, i in enumerate(list_kernel):\n",
    "    output = convolve2D(image, i, padding=2)\n",
    "    cv2.imwrite('2Dconvolved5x_' + str(idx) + '.jpg', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fddeee09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(246, 545)\n"
     ]
    }
   ],
   "source": [
    "kernel_1x = np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1] ])\n",
    "kernel_2x = np.array([[-1,-1,-1],[2,2,2],[-1,-1,-1] ])\n",
    "kernel_3x = np.array([[-1,0,-1],[-1,0,-1],[-1,0,-1] ])\n",
    "\n",
    "list_kernel = [kernel_1x, kernel_2x, kernel_3x]\n",
    "image = prepocessing('images/20231023_173739_134.jpg')\n",
    "print(image.shape)\n",
    "for idx, i in enumerate(list_kernel):\n",
    "    output = convolve2D(image, i, padding=2)\n",
    "    cv2.imwrite('2Dconvolved5x_' + str(idx) + '.jpg', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f23a5772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(771, 1000)\n"
     ]
    }
   ],
   "source": [
    "kernel_1x = np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1] ])\n",
    "kernel_2x = np.array([[-1,-1,-1],[2,2,2],[-1,-1,-1] ])\n",
    "kernel_3x = np.array([[-1,0,-1],[-1,0,-1],[-1,0,-1] ])\n",
    "\n",
    "list_kernel = [kernel_1x, kernel_2x, kernel_3x]\n",
    "image = prepocessing('images/cross.jpg')\n",
    "print(image.shape)\n",
    "for idx, i in enumerate(list_kernel):\n",
    "    output = convolve2D(image, i, padding=2)\n",
    "    cv2.imwrite('2Dconvolved5x_' + str(idx) + '.jpg', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75d48dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 1000)\n"
     ]
    }
   ],
   "source": [
    "kernel_1x = np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1] ])\n",
    "kernel_2x = np.array([[-1,-1,-1],[2,2,2],[-1,-1,-1] ])\n",
    "kernel_3x = np.array([[-1,0,-1],[-1,0,-1],[-1,0,-1] ])\n",
    "\n",
    "list_kernel = [kernel_1x, kernel_2x, kernel_3x]\n",
    "image = prepocessing('images/vertical.jpg')\n",
    "print(image.shape)\n",
    "for idx, i in enumerate(list_kernel):\n",
    "    output = convolve2D(image, i, padding=2)\n",
    "    cv2.imwrite('2Dconvolved5x_' + str(idx) + '.jpg', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69a3561",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
