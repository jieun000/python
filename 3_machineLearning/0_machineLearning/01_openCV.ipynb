{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f0d9d62",
   "metadata": {},
   "source": [
    "# <div id=\"openCV\"><a href=\"#top\" style=\"text-decoration: none; color: black;\">OpenCV(Open Source Computer Vision Library)</a></div><small>오픈소스 이미지(동영상) 라이브러리</small>\n",
    "이미지 형식 변환, 필터 처리, 얼굴 인식, 물체 인식, 문자 인식 등 이미지와 관련된 다양한 처리 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946eeae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4cfd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 다운로드\n",
    "import urllib.request as req\n",
    "url = \"http://uta.pw/shodou/img/28/214.png\"\n",
    "req.urlretrieve(url, \"test.png\")\n",
    "\n",
    "# openCV로 읽기\n",
    "import cv2\n",
    "img = cv2.imread(\"test.png\")\n",
    "print(img) # 이미지 화소 데이터 출력\n",
    "\n",
    "# imreadFalse = cv2.imread(\"imreadFalse.png\") # 이미지 없는 경우=> None\n",
    "# print(imreadFalse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d2a233",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a94f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('WindowName', img)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4c73bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"images/lenna.bmp\")\n",
    "if img is None:\n",
    "    print(\"이미지 로딩 실패\")\n",
    "cv2.imshow('WindowName', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44267da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 저장\n",
    "# img = cv2.imread(\"images/lenna.bmp\")\n",
    "# cv2.imwrite(\"images/lenna.png\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898461c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 흑백으로 \n",
    "# img = cv2.imread('images/cat.bmp')\n",
    "img = cv2.imread('images/cat.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "print('type:', type(img))\n",
    "print('shape:', img.shape)\n",
    "\n",
    "if len(img.shape)==2:\n",
    "    print('img은 흑백(grayscale)이다.')\n",
    "elif len(img.shape)==3:\n",
    "    print('img은 컬러(truecolor)이다.')\n",
    "cv2.imshow('Window_name', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8723d3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 크기 변경\n",
    "img1 = cv2.imread('images/cat.bmp')\n",
    "img2 = cv2.resize(img1, (400, 300))\n",
    "\n",
    "cv2.imshow('origin_img', img1)\n",
    "cv2.imshow('resize_img', img2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e36dcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 자르기\n",
    "img1 = cv2.imread('images/lenna.bmp')\n",
    "img2 = img1[200:400, 200:350]\n",
    "img2 = cv2.resize(img2, (512, 512))\n",
    "cv2.imshow('origin_img', img1)\n",
    "cv2.imshow('resize_img', img2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aad52f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def func_cv():\n",
    "    img1 = np.empty((480,640), np.uint8) # 흑백이미지\n",
    "    img2 = np.zeros((480,640,3), np.uint8) # 컬러이미지\n",
    "    img3 = np.ones((480,640), np.uint32) # 1로 채워진 행렬\n",
    "    img4 = np.full((480,640), 0, np.float32) # 0으로 채워진 행렬\n",
    "    \n",
    "    mat1 = np.array([[11,12,13,14],\n",
    "                    [21,22,23,24],\n",
    "                     [31,32,33,34]]).astype(np.uint8)\n",
    "    mat1[0,1] = 100\n",
    "    mat1[2,:] = 200\n",
    "    print(mat1)\n",
    "    \n",
    "func_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de4003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_cv2():\n",
    "    img1 = cv2.imread('images/cat.bmp')\n",
    "    img2 = img1 # \"주소 복사, 같은 위치\"의 공간을 가리키고 있다.\n",
    "    img3 = img1.copy() # 깊은 복사(deep copy)\n",
    "    img1[:,:] = (0,255,255) # yellow (255,0,0)=(파랑)\n",
    "    \n",
    "    cv2.imshow('img1', img1)\n",
    "    cv2.imshow('img2', img2)\n",
    "    cv2.imshow('img3', img3)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "func_cv2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099676d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_cv3():\n",
    "    img1 = cv2.imread('images/lenna.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "#     img2 = img1[200:400,200:400]\n",
    "    img2 = img1[200:400,200:400].copy()\n",
    "    img3 = img1[200:400,200:400].copy()\n",
    "    img2 += 20\n",
    "    print('shape: ', img1.shape, 'shape2: ', img2.shape)\n",
    "    print('img1:', img1[200:400,200:400][0],'img2:',img2[:,:],[0])\n",
    "    cv2.imshow('img1', img1)\n",
    "    cv2.imshow('img2', img2)\n",
    "    cv2.imshow('img3', img3)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "func_cv3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f3ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_cv4():\n",
    "    mat1 = np.array(np.arange(12)).reshape(3,4)\n",
    "    print('mat:')\n",
    "    print(mat1)\n",
    "    \n",
    "    h, w = mat1.shape[:2]\n",
    "    mat2 = np.zeros(mat1.shape, type(mat1))\n",
    "    for j in range(h):\n",
    "        for i in range(w):\n",
    "            mat2[j,i] = mat1[j,i] + 10\n",
    "    print('mat2: ')\n",
    "    print(mat2)\n",
    "    \n",
    "func_cv4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83208aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_cv5():\n",
    "    mat1 = np.zeros((3,4),np.int32)\n",
    "    mat2 = np.arange(12).reshape(3,4)\n",
    "    mat3 = mat1 + mat2\n",
    "    mat4 = mat2 * 2\n",
    "    print(\"mat1: \", mat1, sep=\"\\n\")\n",
    "    print(\"mat2: \", mat2, sep=\"\\n\")\n",
    "    print(\"mat3: \", mat3, sep=\"\\n\")\n",
    "    print(\"mat4: \", mat4, sep=\"\\n\")\n",
    "    \n",
    "func_cv5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af5ab43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# img1의 이미지의 밝기가 70~150(중간 밝기) 사이인 것을\n",
    "# BGR # (BGR)/3(색상의 평균값이) => 70~150(중간 밝기)\n",
    "# img1의 이미지의 밝기를 255(흰색)로 변경함\n",
    "\n",
    "def func_cv6():\n",
    "    img1 = cv2.imread('images/lenna.bmp')\n",
    "    # 0이면 Blue, 1이면 Green, 2면 Red\n",
    "    avg = ((img1[:,:,1] + img1[:,:,0] + img1[:,:,2] / 3.0)) # RGB평균\n",
    "    avg_int = avg.astype(np.uint8) # 실수를 정수로 변환\n",
    "    print(avg_int, 'before: ',avg_int.shape)\n",
    "    boolean_arr = (avg_int[:,:] > 75) & (avg_int[:,:] <= 80) # 픽셀 값이 75~200사이\n",
    "    my_index_true = np.where(boolean_arr) # True인 index 찾기\n",
    "#     avg_int[my_index_true==True]=240 # 해당 index의 값을 255로 설정\n",
    "    print(avg_int, 'after: ',avg_int.shape)\n",
    "    \n",
    "    cv2.imshow('avg_int',avg_int)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "func_cv6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda80d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_eunyeong():\n",
    "    img1 = cv2.imread('images/lenna.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "    img2 = img1[:,:].copy()\n",
    "    mask = (img2 >= 70) & (img2 <= 150)\n",
    "    img2[mask] = (50)\n",
    "    \n",
    "    cv2.imshow('img1',img1)\n",
    "    cv2.imshow('img2',img2)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "func_eunyeong()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8678bb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img1의 이미지의 크기에서 중간 영역(좌표 200:300, 200:400)의 밝기를 0으로 설정함\n",
    "def func_cv7():\n",
    "    img1 = cv2.imread('images/lenna.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "    img2 = img1[:,:].copy()\n",
    "    img2[200:300, 200:400] = 0\n",
    "    \n",
    "    cv2.imshow('img1',img1)\n",
    "    cv2.imshow('img2',img2)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "func_cv7()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310fdfb5",
   "metadata": {},
   "source": [
    "얼굴 검출 캐스케이드 파일(얼굴 요소 데이터베이스): OpenCV와 함께 저장되지만 최신 버전 받으려면~?\n",
    "[URL](https://github.com/opencv/opencv/tree/master/data/haarcascades)\n",
    "\n",
    "- 과정\n",
    "    1. 캐스케이드 파일을 지정해 검출기 생성.\n",
    "    2. 대상 이미지를 읽어 그레이스케일로 변환.\n",
    "    3. 얼굴 검출 실행."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf99b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib.request as req\n",
    "# url = \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_alt.xml\"\n",
    "# savefile = \"files/haarcascade_frontalface_alt.xml\"\n",
    "# req.urlretrieve(url, savefile)\n",
    "# print(\"저장 완료.\")\n",
    "\n",
    "import cv2\n",
    "# 캐스케이드 파일 지정해 검출기 생성\n",
    "cascade_file = \"files/haarcascade_frontalface_alt.xml\"\n",
    "cascade = cv2.CascadeClassifier(cascade_file)\n",
    "\n",
    "img = cv2.imread(\"images/lenna.bmp\")\n",
    "img_gray = cv2.imread(\"images/lenna.bmp\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 얼굴 인식. minSize(얼굴 인식 영역의 최소 크기)\n",
    "face_list = cascade.detectMultiScale(img_gray, minSize=(150, 150))\n",
    "\n",
    "# 결과 확인.\n",
    "if len(face_list) == 0:\n",
    "    print(\"실패다. 띠로린~\")\n",
    "    quit()\n",
    "    \n",
    "# 인식한 부분 표시.\n",
    "for x, y, w, h in face_list:\n",
    "    print(\"얼굴 좌표: \", x, y, w, h)\n",
    "    red = (255, 255, 0)\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), red, thickness=20)\n",
    "\n",
    "cv2.imshow(\"result\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61283ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모자이크\n",
    "import cv2\n",
    "\n",
    "def mosaic(img, rect, size):\n",
    "    # 모자이크 적용할 부분 추출.\n",
    "    (x1, y1, x2, y2) = rect\n",
    "    w = x2 - x1\n",
    "    h = y2 - y1\n",
    "    i_rect = img[y1:y2, x1:x2]\n",
    "    # 축소와 확대를 사용해 모자이크 생성\n",
    "    i_small = cv2.resize(i_rect, (size, size))\n",
    "    i_mos = cv2.resize(i_small, (w, h), interpolation=cv2.INTER_AREA)\n",
    "    # 모자이크 적용\n",
    "    img2 = img.copy()\n",
    "    img2[y1:y2, x1:x2] = i_mos\n",
    "    return img2\n",
    "\n",
    "img = cv2.imread(\"images/aegi_cat.jpg\")\n",
    "mos = mosaic(img, (140, 230, 350, 280), 10)\n",
    "\n",
    "cv2.imshow(\"result\", mos)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7075c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img1 = cv2.imread('images/aegi_cat.jpg')\n",
    "img2 = img1[:,:].copy()\n",
    "img2[250:270,190:295] = 0\n",
    "\n",
    "cv2.imshow('img1',img1)\n",
    "cv2.imshow('img2',img2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49e92073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "얼굴 좌표:  202 193 196 196\n"
     ]
    }
   ],
   "source": [
    "# 사람 얼굴에 자동으로 모자이크 처리\n",
    "import cv2\n",
    "\n",
    "def mosaic(img, rect, size):\n",
    "    # 모자이크 적용할 부분 추출.\n",
    "    (x1, y1, x2, y2) = rect\n",
    "    w = x2 - x1\n",
    "    h = y2 - y1\n",
    "    i_rect = img[y1:y2, x1:x2]\n",
    "    # 축소와 확대를 사용해 모자이크 생성\n",
    "    i_small = cv2.resize(i_rect, (size, size))\n",
    "    i_mos = cv2.resize(i_small, (w, h), interpolation=cv2.INTER_AREA)\n",
    "    # 모자이크 적용\n",
    "    img2 = img.copy()\n",
    "    img2[y1:y2, x1:x2] = i_mos\n",
    "    return img2\n",
    "\n",
    "# 캐스케이드 파일 지정해 검출기 생성\n",
    "cascade_file = \"files/haarcascade_frontalface_alt.xml\"\n",
    "cascade = cv2.CascadeClassifier(cascade_file)\n",
    "\n",
    "img = cv2.imread(\"images/example.jpg\")\n",
    "img_gray = cv2.imread(\"images/example.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 얼굴 인식. minSize(얼굴 인식 영역의 최소 크기)\n",
    "face_list = cascade.detectMultiScale(img_gray, minSize=(150, 150))\n",
    "if len(face_list) == 0: quit()\n",
    "    \n",
    "# 인식한 부분 표시.\n",
    "for x, y, w, h in face_list:\n",
    "    print(\"얼굴 좌표: \", x, y, w, h)\n",
    "    img = mosaic(img, (x, y, x+w, y+h), 10)\n",
    "\n",
    "cv2.imshow(\"result\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
